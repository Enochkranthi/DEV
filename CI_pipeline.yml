# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger: none

pool:
  vmImage: ubuntu-latest

variables:
- group: 'DEV'

steps:
- script: echo Hello, world!
  displayName: 'Run a one-line script'

- script: |
    echo See https://aka.ms/yaml
  displayName: 'Run a multi-line script'

- script: pip install databricks-cli
  displayName: 'Install Databricks cli'

- script: |
    echo "$(databricksHost)
    $(DB_PAT)" | databricks configure --token
  displayName: 'configure databricks cli'

- script: databricks workspace ls
  displayName: 'test databricks cli'

- script: databricks repos delete --path /Repos/prakashpoorna998@gmail.com/DEV
  displayName: 'Deleting old repo'

- script: databricks repos create --url https://github.com/Enochkranthi/DEV.git --provider gitHub --path /Repos/prakashpoorna998@gmail.com/DEV
  displayName: 'Importing git repo'
    
- script: |
      json_path=$(Build.SourcesDirectory)/MLOps/dev-cluster.json
      databricks clusters create --json-file "$json_path"
      cluster_id=$(databricks clusters get --cluster-name Small | jq -r '.cluster_id')
  displayName: 'Create Cluster'

- script: |
      while true; do
        cluster_status=$(databricks clusters get --cluster-name Small | jq -r '.state')
        if [[ $cluster_status == "RUNNING" ]]; then
          break
        fi
        sleep 10
      done
